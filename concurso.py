# -*- coding: utf-8 -*-
"""concurso.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eM3O6Mnbq0hLW8Z-rqJfkL8DPPyipJ4u

### bibliotecas
"""

!pip install pandas==1.5.3

!pip install lxml

from urllib.request import urlopen,urlretrieve
from urllib.error import HTTPError
from bs4 import BeautifulSoup
import pandas as pd
import os
from datetime import datetime
from tqdm import tqdm

from google.colab import drive
drive.mount('/content/drive')

"""## Funçoes Gerais

### Extrair paginas
"""

def ExtractPage(url, ReturnErro =None):
  try:
    html = urlopen(url)
  except HTTPError as e:
    return ReturnErro
  try:
    page = BeautifulSoup(
        html.read().decode('utf8'), 'lxml')
  except AttributeError as e:
    return ReturnErro
  return page

"""### Salvando CSV"""

def SaveFileCSV(path, name, dataFrame):

  if not os.path.exists(path):
    os.makedirs(path)
    
  return dataFrame.to_csv(path + name, Index=False)

Data.info()

"""## Extracao de dados

### Extração de cargos e seus link

criar padrao de extração e com paramentro
"""

def extractOfficersPath():
  
  url = 'https://www.pciconcursos.com.br/provas/'
  filePath = 'bronze/path_officers/'
  data = datetime.today().strftime('%Y-%m-%d')
  officersLinkList = []
  
  page = ExtractPage(url)
 
  for tag in page.find_all("a", title=True):
    office = tag.text
    link = tag['href']

    officersLinkList.append([office, link])
  
  officersLink = pd.DataFrame(officersLinkList, columns=['office','link'])

  SaveFileCSV(filePath, f'path_office_{data}.csv', officersLink )

extractOfficersPath()

"""## Paginas provas"""

def ReadOfficePath():

  date = datetime.today().strftime('%Y-%m-%d')
  OfficersLink = pd.read_csv(f'bronze/path_officers/path_office_{date}.csv')

  return OfficersLink.values #limitador

def ExtractOfficeData():
  date = datetime.today().strftime('%Y-%m-%d')

  with tqdm(total=515) as barra:
    for office, link in ReadOfficePath():
      name = link.split('/')[-1]+'_'+date
      office = office.replace(" ","_")
      path = f'bronze/data_officers/{office}/'

      ExportDF = pd.DataFrame()
      
      page = ExtractPage(link)

      NPage = int(page.find_all("span")[1].text.split()[-1])
    
      if NPage != 1:
        

        for n in range(1, NPage + 1):
          linkPage = f'{link}/{n}'
          
          page = ExtractPage(link)

          PageDF = pd.read_html(link, header = 0, extract_links='all')[0]
          ExportDF = pd.concat([ExportDF, PageDF])
      
        SaveFileCSV(path, name+".csv", ExportDF)

      else:
        ExportDF = pd.read_html(link, header = 0, extract_links='all')[0]
        

        SaveFileCSV(path, name+".csv", ExportDF)

      barra.update(1)

"""## Rodando """

ExtractOfficeData()

"""## Do classificarção bronze para prata

### Codigo
"""

def limpezaSeparaColuna(path):
  
  data = pd.read_csv(path)
  #data.drop(index=0, inplace=True)
 
  listColumns = data.columns

  tirar = ["'",")","("]
  for nomeColuma in listColumns:
     data[nomeColuma] = data[nomeColuma].str.translate(str.maketrans('','',"".join(tirar)))
  
  data[['prova','linkProva']]= data[listColumns[0]].str.rsplit(',', n=1, expand=True)
  data['ano']= data[listColumns[1]].str.split(',', expand=True)[0]
  data['nivel']= data[listColumns[4]].str.split(',', expand=True)[0]
  data[['orgaoEstado','linkOrgao']]= data[listColumns[2]].str.rsplit(',', n=1, expand=True)
  data['orgao']  = [orgaoEstado.split('/')[0] if "/" in orgaoEstado else orgaoEstado for orgaoEstado in data['orgaoEstado']]
  data['estado'] = [orgaoEstado.split('/')[1] if "/" in orgaoEstado else 'null' for orgaoEstado in data['orgaoEstado']]
  data[['banca','linkBanca']]= data[listColumns[3]].str.rsplit(',', n=1, expand=True)

  data.drop(columns=listColumns, inplace=True)
  return data

def padraoPrataData():
  caminhos = os.listdir('drive/MyDrive/data/bronze/data_officers/')
  
  dataFame = pd.DataFrame()
  with tqdm(total=515) as barra:
    for pasta in caminhos:
      arquivo = os.listdir(f'drive/MyDrive/data/bronze/data_officers/{pasta}')
      path = f"drive/MyDrive/data/bronze/data_officers/{pasta}/{arquivo[0]}"
     
      
      #print(path)
      
      data = limpezaSeparaColuna(path)
      

      dataFame = pd.concat([dataFame, data])
      
      barra.update(1)

  SaveFileCSV('prata/compila/', f'data.csv', dataFame)

"""### """

padraoPrataData()

"""## vai """

data = pd.read_csv("prata/compila/data.csv")
data.drop(columns='Unnamed: 0', inplace=True)

data.query("orgao == 'MP'")

"""## Provas"""

def listaProvas():
  caminhos = [[f'bronze/data_officers/{pasta}/{arquivo}' for arquivo in os.listdir(f'bronze/data_officers/{pasta}') ] for pasta in os.listdir('bronze/data_officers/') if '.' != pasta[0]]
  listaCargo =[pasta for pasta in os.listdir('bronze/data_officers/') if '.' != pasta[0]]
  for caminho in caminhos:
    print(caminho)
    #df = pd.read_csv(caminho[0])
    #return df.values
  #return listaCargo
listaProvas()

def BaixandoProvas(): 
  numero = 0
  for prova in listaProvas():
    
    pagina = ExtractPage(prova[0])

    pasta = prova[0].split("/")[-1]
    data = datetime.today().strftime('%Y-%m-%d')

    for tag in pagina.find_all('ul',{'class':'pdf_download'}):
      file_prova = pagina.find_all('li')[0].a['href']
      file_gabarito = pagina.find_all('li')[1].a['href']

      nome = pasta.split('-')[0]
      file_path = f'provas/{nome}-{data}/{pasta}'
      if not os.path.exists(file_path):
        os.makedirs(file_path)

      urlretrieve(file_prova , f"{file_path}/prova.pdf" )
      urlretrieve(file_gabarito , f"{file_path}/gabarito.pdf")
      numero += 1
  print(numero)

BaixandoProvas()
